# --- Required ---
# Your API key for the Gemini model. This is essential for the application to work.
GEMINI_API_KEY="AIzaSyBybth8NfYlNxjT8hfP-whMn9q2rDV657I"

# -----------------------------------------------------------------------------
# OPTIONAL: PERFORMANCE & CONCURRENCY TUNING
# These settings control how the RAG system processes data and interacts with APIs.
# -----------------------------------------------------------------------------

# The maximum number of concurrent API calls to the Gemini LLM.
# This helps manage rate limits and control costs. A good starting point is 4.
MAX_ASYNC_LLM_CALLS=4

# The maximum number of concurrent embedding operations.
# Since embeddings run locally on your CPU, you can set this higher.
# A good starting point is 8, or twice your LLM concurrency.
MAX_ASYNC_EMBEDDING_CALLS=8

# The maximum number of files to process in parallel during the initial ingestion stage.
# Keep this low (1-4) to avoid high CPU/memory usage on your server.
MAX_PARALLEL_INSERT=2

# The number of times to re-attempt entity extraction for better results.
# A value of 1 is standard. Increasing this will increase processing time and cost.
MAX_GLEANING=1


# -----------------------------------------------------------------------------
# OPTIONAL: RAG BEHAVIOR TUNING
# These settings control the behavior of the chat and query logic.
# -----------------------------------------------------------------------------

# The number of recent conversation turns (a user message + an assistant response = 1 turn)
# to include in the context for the next query.
HISTORY_TURNS=3


# -----------------------------------------------------------------------------
# OPTIONAL: LOGGING CONFIGURATION
# -----------------------------------------------------------------------------

# The directory where log files will be stored.
# If not set, logs will be created in the same directory as the script.
LOG_FILE_PATH="./rag_server.log"